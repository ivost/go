
package main

// https://golang.org/pkg/runtime/pprof/
// go test -cpuprofile cpu.prof -memprofile mem.prof -bench .
// Package pprof serves via its HTTP server runtime profiling data
// https://github.com/google/pprof
// go tool pprof http://localhost:6060/debug/pprof/heap

import (
	"fmt"
	"log"
	"net/http"
	"os"
	"runtime"
	"runtime/pprof"
	"time"

	_ "net/http/pprof"

	"github.com/golang/go/src/pkg/io"
	"github.com/golang/go/src/pkg/strings"

	"bitbucket.org/smartdrive_systems/cdp/networking/h2c"
)

var cpuprof = "cpu.prof"
var memprof = "mem.prof"

func main() {

	if profileCpu() {
		defer pprof.StopCPUProfile()
	}

	log.Printf("h2c server 0.0.1")

	// handler for /foo
	http.HandleFunc("/foo", write1)

	// handler for /bar
	http.HandleFunc("/bar", func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte("bar"))
	})

	http.HandleFunc("/quit", func(w http.ResponseWriter, r *http.Request) {
		profileMem()
		pprof.StopCPUProfile()
		log.Println("EXIT")
		os.Exit(0)
	})

	println("h2c server listening on port 8080 - see client to send GET ")
	println("to test with http2: curl -i --http2 localhost:8080/foo")
	println("to test with http: curl -i localhost:8080/foo")
	println("prefix with GODEBUG=http2debug=1 or 2 for debugging")
	err := http.ListenAndServe(":8080", &h2c.Server{})
	log.Fatal(err)
}

func write1(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "text/plain")
	fmt.Fprintf(w, "%v\n", time.Now())
	fmt.Fprintf(w, "# ~1KB of junk to force browsers to start rendering immediately: \n")
	io.WriteString(w, strings.Repeat("# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n", 13))
	w.(http.Flusher).Flush()
}

func profileCpu() bool {
	if cpuprof == "" {
		return false
	}

	f, err := os.Create(cpuprof)
	if err != nil {
		fmt.Printf("Error creating cpu.prof: %v\n", err)
		return false
	}
	fmt.Printf("StartCPUProfile %s\n", cpuprof)
	if err := pprof.StartCPUProfile(f); err != nil {
		fmt.Printf("could not start CPU profile: %v\n", err)
		return false
	}
	return true
}

func profileMem() bool {
	if memprof == "" {
		return false
	}
	f, err := os.Create(memprof)
	if err != nil {
		fmt.Printf("could not create memory profile: %v\n", err)
		return false
	}
	fmt.Printf("StartHeapProfile %s\n", memprof)
	runtime.GC() // get up-to-date statistics
	if err := pprof.WriteHeapProfile(f); err != nil {
		fmt.Printf("could not write memory profile: %v\n", err)
		return false
	}
	f.Close()
	return true
}
----



https://github.com/americanexpress/baton

Using Baton
Baton currently supports the following options:

  -b string
    	Body (use instead of -f)
  -c int
    	Number of concurrent requests (default 1)
  -f string
    	File path to file to be used as the body (use instead of -b)
  -i	Ignore TLS/SSL certificate validation
  -m string
    	HTTP Method (GET,POST,PUT,DELETE) (default "GET")
  -o	Supress output, no results will be printed to stdout
  -r int
    	Number of requests (use instead of -t) (default 1)
  -t int
    	Duration of testing in seconds (use instead of -r)
  -u string
    	URL to run against
  -w int
    	Number of seconds to wait before running test
  -z string
    	Read requests from a file


on mac

baton -u http://localhost:8080/foo -c 10 -r 1000



func clockStreamHandler(w http.ResponseWriter, r *http.Request) {
	clientGone := w.(http.CloseNotifier).CloseNotify()
	w.Header().Set("Content-Type", "text/plain")
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()
	fmt.Fprintf(w, "# ~1KB of junk to force browsers to start rendering immediately: \n")
	io.WriteString(w, strings.Repeat("# xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n", 13))

	for {
		fmt.Fprintf(w, "%v\n", time.Now())
		w.(http.Flusher).Flush()
		select {
		case <-ticker.C:
		case <-clientGone:
			log.Printf("Client %v disconnected from the clock", r.RemoteAddr)
			return
		}
	}
}





	http.HandleFunc("/hijack", func(w http.ResponseWriter, r *http.Request) {
		hj, ok := w.(http.Hijacker)
		if !ok {
			http.Error(w, "webserver doesn't support hijacking", http.StatusInternalServerError)
			return
		}
		conn, bufrw, err := hj.Hijack()
		if err != nil {
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
		// Don't forget to close the connection:
		defer conn.Close()
		bufrw.WriteString("Now we're speaking raw TCP. Say hi: ")
		bufrw.Flush()
		s, err := bufrw.ReadString('\n')
		if err != nil {
			log.Printf("error reading string: %v", err)
			return
		}
		log.Printf("hijack: %v", s)
		fmt.Fprintf(bufrw, "You said: %q\nBye.\n", s)
		bufrw.Flush()
	})
    




~/p/g/s/b/s/s/g/x/h/client ❯❯❯ baton -u http://localhost:8080/foo -c 8 -r 100000                  (git)-[go]-
Configuring to send GET requests to: http://localhost:8080/foo
Generating the requests...
Finished generating the requests
Sending the requests to the server...
Finished sending the requests
Processing the results...


====================== Results ======================
Total requests:                                100000
Time taken to complete requests:         1.753006054s
Requests per second:                            57045
Max response time (ms):                          1561
Min response time (ms):                            47
Avg response time (ms):                        139.01
===================== Breakdown =====================
Number of connection errors:                        0
Number of 1xx responses:                            0
Number of 2xx responses:                       100000
Number of 3xx responses:                            0
Number of 4xx responses:                            0
Number of 5xx responses:                            0
=====================================================


aton -u http://192.168.6.100:8080/foo -c 2 -r 10000               (git)-[go]-
Configuring to send GET requests to: http://192.168.6.100:8080/foo
Generating the requests...
Finished generating the requests
Sending the requests to the server...
Finished sending the requests
Processing the results...


====================== Results ======================
Total requests:                                 10000
Time taken to complete requests:         8.990199526s
Requests per second:                             1112
Max response time (ms):                          9748
Min response time (ms):                           692
Avg response time (ms):                        1795.47
===================== Breakdown =====================
Number of connection errors:                        0
Number of 1xx responses:                            0
Number of 2xx responses:                        10000
Number of 3xx responses:                            0
Number of 4xx responses:                            0
Number of 5xx responses:                            0
=====================================================


baton -u http://192.168.6.100:8080/foo -c 8 -r 100000                  (git)-[go]-

baton -u http://192.168.6.100:8080/foo -c 8 -r 100000              (git)-[go]-
Configuring to send GET requests to: http://192.168.6.100:8080/foo
Generating the requests...
Finished generating the requests
Sending the requests to the server...
Finished sending the requests
Processing the results...


====================== Results ======================
Total requests:                                100000
Time taken to complete requests:        25.379005881s
Requests per second:                             3940
Max response time (ms):                          8326
Min response time (ms):                           617
Avg response time (ms):                        2028.90
===================== Breakdown =====================
Number of connection errors:                        0
Number of 1xx responses:                            0
Number of 2xx responses:                       100000
Number of 3xx responses:                            0
Number of 4xx responses:                            0
Number of 5xx responses:                            0
=====================================================


baton -u http://192.168.6.100:8080/foo -c 10 -r 10000              (git)-[go]-
Configuring to send GET requests to: http://192.168.6.100:8080/foo
Generating the requests...
Finished generating the requests
Sending the requests to the server...
Finished sending the requests
Processing the results...


====================== Results ======================
Total requests:                                 10000
Time taken to complete requests:         3.245526695s
Requests per second:                             3081
Max response time (ms):                         10671
Min response time (ms):                           774
Avg response time (ms):                        3240.24
===================== Breakdown =====================
Number of connection errors:                        0
Number of 1xx responses:                            0
Number of 2xx responses:                        10000
Number of 3xx responses:                            0
Number of 4xx responses:                            0
Number of 5xx responses:                            0
=====================================================







